from pickle import FALSE 
import cv2 as cv                                    #to capture slide and webcam
import os                                           #to add the folder with current program
from cvzone.HandTrackingModule import HandDetector  #to detect hands movement and gestures
import numpy as np
from pyparsing import annotations #to calculate co-ordinates
import speech_recognition as sr                     #to implement voice controls


# Variables 
 
width, height = 1000, 600
folderPath = r"C:\Users\hp\Desktop\New folder"


# camera setup

cap = cv.VideoCapture(0)

cap.set(3, width)
cap.set(4, height)

# get the list of presentation images

path_images = sorted(os.listdir(folderPath), key=len)

#variables
imgNumber = 0
hs, ws = int(120 * 1.8), int(213 * 1.8)
gestureThreshold = 350
buttonpressed = False
buttoncounter = 0
delaycounter = 20

#variables used in drawing and erasing 
annotations = [[]]
annotationNumber = -1
annotationStart = False
voiceAnnotation = False

#implement zoom functioning
zoomScale = 1.0
zoomCenter = (width // 2, height // 2)
initialDistance = None

# function to detect hands
detector = HandDetector(detectionCon=0.85, maxHands=2)


#function to get voice recognition
def get_voice_command():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening you ...")
        r.adjust_for_ambient_noise(source, duration=1)
        audio = r.listen(source)
        try:
            text = r.recognize_google(audio)
            print("You said:", text)
            return text.lower()
        except Exception as e:
            print("Could not understand audio:", e)
            return ""


#implment the loop when hands are detected
while True:

    success, img = cap.read()
    img = cv.flip(img, 1)

    pathFullImage = os.path.join(folderPath, path_images[imgNumber])    #retrun the list of images in sorted order from given folder path
    imgCurrent = cv.imread(pathFullImage)

    hands, img = detector.findHands(img)    #detect hands

    cv.line(img, (0, gestureThreshold), (width, gestureThreshold), (255, 0, 0), 5) #threshold line to prevent disturbance

    if hands and not buttonpressed:
        hand = hands[0]
        fingers = detector.fingersUp(hand)  #detect fingertips and return a list 

        #drawing portions
        #  
        x, y = hand['center']
        lmList = hand['lmList']

        xVal = int(np.interp(lmList[8][0], [0, width], [0, width])) #represent index finger
        yVal = int(np.interp(lmList[8][1], [150, height - 150], [0, height])) #represent middle finger
        indexFinger = xVal, yVal

        # When hands are above the threshold line
        if y <= gestureThreshold:

            # Gesture 01 Move to previous slide
            if fingers == [1, 0, 0, 0, 0] and imgNumber > 0:
                buttonpressed = True

                #To remove all drawings when you move to next page
                annotations = [[]]
                annotationNumber = -1
                annotationStart = False
                imgNumber -= 1


            # Gesture 02 Move to next slide
            if fingers == [0, 0, 0, 0, 1] and imgNumber < len(path_images) - 1:
                buttonpressed = True
                annotations = [[]]
                annotationNumber = -1
                annotationStart = False
                imgNumber += 1

            if fingers == [0, 1, 0, 0, 1]:  # Gesture 03 Exit the window
                break
        
        # Gesture 04 Show pointer used for drawing 
        if fingers == [0, 1, 1, 0, 0]:
            cv.circle(imgCurrent, indexFinger, 22, (0, 0, 255), cv.FILLED)

        # Gesture 05 Draw with Indexfinger 
        if fingers == [0, 1, 0, 0, 0]:
            if not annotationStart:
                annotationStart = True
                annotationNumber += 1
                annotations.append([])

            cv.circle(imgCurrent, indexFinger, 22, (0, 0, 255), cv.FILLED)
            annotations[annotationNumber].append(indexFinger)

        else:
            annotationStart = False

        # Gesture 06 Erase last stroke 
        if fingers == [0, 1, 1, 1, 0]:
            if annotations:
                annotations.pop(-1)
                annotationNumber -= 1
                buttonpressed = True

        #Gesture 07 Zoom current slide
        if fingers == [1, 1, 0, 0, 0]:  
            x1, y1 = lmList[4][0], lmList[4][1]
            x2, y2 = lmList[8][0], lmList[8][1]
            currentDistance = np.hypot(x2 - x1, y2 - y1)

            if initialDistance is None:
                initialDistance = currentDistance

            zoomFactor = currentDistance / initialDistance
            zoomScale = np.clip(zoomFactor, 0.5, 2.0)
            zoomCenter = ((x1 + x2) // 2, (y1 + y2) // 2)

        else:
            initialDistance = None

    else:
        annotationStart = False

    # process to generate a delay when traversing slides  
    if buttonpressed:
        buttoncounter += 1
        if buttoncounter > delaycounter:
            buttoncounter = 0
            buttonpressed = False

    #draw line when and add it to annottion list  
    for i in range(len(annotations)):
        for j in range(len(annotations[i])):
            if j != 0:
                cv.line(imgCurrent, annotations[i][j - 1], annotations[i][j], (0, 125, 23), 12)


    #Resize imgCurrent based on zoomScale
    zoomedSlide = cv.resize(imgCurrent, None, fx=zoomScale, fy=zoomScale)

    # Create a black canvas of the original size
    canvas = np.zeros_like(imgCurrent)

    zh, zw = zoomedSlide.shape[:2]
    cx, cy = zoomCenter  # Center of zoom (usually width//2, height//2)

    # Coordinates to crop from zoomed image
    startX = zw // 2 - width // 2
    startY = zh // 2 - height // 2

    # Clamp to valid range
    startX = max(0, startX)
    startY = max(0, startY)
    endX = startX + width
    endY = startY + height

    # Crop the zoomed slide centered
    croppedZoom = zoomedSlide[startY:endY, startX:endX]

    # If cropped area is smaller than canvas (e.g., zoom out too much), pad it
    finalZoom = np.zeros_like(imgCurrent)
    ch, cw = croppedZoom.shape[:2]
    finalZoom[0:ch, 0:cw] = croppedZoom

    imgCurrent = finalZoom

    #Important windows 
    cv.imshow("Image", img)
    cv.imshow("Slide", imgCurrent)

    key = cv.waitKey(1) #waiting key


    #break the loop
    if key == ord('q'):
        break

    # acessing voice controls with by pressing 'v'    
     if key == ord('v'):
        command = get_voice_command()
        if "next" in command or "next slide" in command or "move to the next slide" in command or "next page" in command :
            if imgNumber < len(path_images) - 1:
                imgNumber += 1
                print("Next Slide")
                annotations = [[]]
                annotationNumber = -1
                annotationStart = False
        elif "previous" in command or "move to the last slide" in command or "last slide" in command or "back" in command or "previous slide" in command or "previous page" in command:
            if imgNumber > 0:
                imgNumber -= 1
                print("Previous Slide")
                annotations = [[]]
                annotationNumber = -1
                annotationStart = False
        elif "zoom in" in command:
            zoomScale = min(zoomScale + 0.1, 2.0)
            print("Zoom In")
        elif "zoom out" in command:
            zoomScale = max(zoomScale - 0.1, 0.5)
            print("Zoom Out")
        elif "undo" in command:
            if annotations and annotationNumber >= 0:
                annotations.pop(annotationNumber)
                annotationNumber -= 1
                print("Undo last stroke")
       elif "erase" in command or "clear" in command or "clear screen" in command or "remove" in command:
            annotations = [[]]
            annotationNumber = -1
            annotationStart = False
            print("Erase all drawing")
        elif "exit" in command or "done for today" in command or "close" in command or "thank you" in command or "bye bye" in command:
            print("Exiting by voice command.")
            break

#Release the camera and close all windows   
cap.release()
cv.destroyAllWindows()
